---
layout : post
title : biz_statistics_ANOVA
categories : - Data Science
tags : - Basic statistics
---

## Objective

- 표본 평균에 차이에 대한 가설검정의 도구로 ANOVA(분산분석)을 설명할 수 있다.
- 세 집단 이상의 평균값에 대한 가설 검정을 실시 할 수 있다.
- 분산 분석의 결과를 설명할 수 있다.

## Analysis of Variation(분산분석)

#### terminology 

- Factor 요인 : 이제 집단이 왜 나뉘지에 대한 관심을 갖기 시작함. 성별? 학교?
- Treatment : 요인의 값들 (학교가 factor면 서울대 연세대 고려대 등)
- One-way ANOVA 일원분산분석
- Two-way ANOVA 이원분산분석 : Factor를 두개 (그 이상일땐 다른 분석방법 씀)
- Replication : 각각의 집단마다 데이터가 1개밖에 없다면 분포를 상상할 수 없다. 즉 반복이 없다는 건데 
이럴때와 집단의 데이터가 많을때가 조금 다르다.
- Interaction 교호작용 : 요인들끼리 서로 영향을 끼치는 관계인지 확인해야함


#### 분산분석

- t-test의 확장판 (t는 두집단의 평균비교)
- 분산분석은 분산을 비교하는게아니라 두 집단 이상의 평균 비교 하는 것
- 가정
1. 표본집단은 정규분포를 따름 (표본집단의 평균은 central theorem에 의해서 정규분포)
2. 표본은 독립/무작위 표본 추출법에 의해 추출
3. 각 모집단은 동일한 표준편차를 가진다(동분산가정).

- F분포를 쓴다(두집단의 분산을 비교할때 썼던거)
- 방법은 똑같음 (가설검정 프로세스)


#### 가설검정

- H0 : u1=u2=u3=...=uk
- H1 : 집단들 중에 다른놈이 있다.

누가 다른놈인지는 알수가 없다. 근데 왜 하는가?
우리가 대학교 세군대의 몸무게가 같은지 실험해보자.
상식적으로는 같아야하는데 만약 분산분석의 결과가 다르다고 나왔다 치자.
그러면 대학교라는 인자가 몸무게에 영향을 끼친다는 사실을 알 수 있기 때문에 하는거임. 
그 이후엔 이유를 찾는거지. 예를들면 언덕, 위치, 대중교통 유무 등.
결국 그 원인을 통해 결과가 달라진다는 사실을 알아내는것.

- Fdist의 자유도는 (k-1, n-k)가 들어감


#### 예제

임플란트에는 4mm, 6mm, 8mm의 폭을 가진 가이드에 따라서 시술 됨.
각각의 가이드에 대해 15개의 임플란트가 시술 되었는데요.
각각의 임플란트 가이드 대비 오차의 평균 0.236/ 0.26/ 0.248 정도라고 합시다.
그럼 가이드 폭의 차가 에러의 크기에 영향을 주는걸까요??

- H0 : u4 = u6 = u8
- H1 : 집단끼리 다르다
- 45개 데이터 전체 평균이 0.248mm ( 평균의 평균 = Grand mean )
- 각각 집단의 평균값이 Grand mean과의 거리가 멀면 멀수록 다른놈이 존재할 확률이 크다는 뜻
- 데이터의 개수가 많을수록 거리합에 영향을 많이 주므로 가중치의 의미로 앞에 곱해줌
- SSB= Sum of Square Between groups (집단간 거리의 제곱합)  

```
SSB = 15(0.236-0.248)^2 + 15(0.26-0.28)^2 + 15(0.248-0.28)^2  = 0.0047  
그럼 이 거리의 제곱이 H0을 기각할 만큼 충분히 클까??  
이걸로 기각하긴 어려우니 분산의 개념을 도입하자고 수학자들이 생각함  
```

#### 총분산의 분리
Total variation은 2개로 나뉠 수 있음.

- Variation due to treatment  
SSB가 클수록 기각될 확률이 크다
- Variation due to random sampling  
SSE가 작을수록 기각될 확률이 크다


#### 아 이건 그림없이 무리다(사진추가)

#### 일원분산의 기본개념

1. 2개 집단이상의 평균을 비교함에 있어서 산출되는 2가지 종류의 분산을 비교하는 것이다.
2. 처리의 분산(SSB)와 무작위분산(SSE)를 비교해서 처리의 분산이 유의미하게 크다면 이는 집단간 평균값이 다르다는 의미다.
3. SSE와 SSB 모두 거리로 계산해서 실제 분산계산시 들어가는 데이터 갯수가 빠짐
4. F-test를 하려면 통계적 분산이 필요해서 MST(Mean Square Treatment), MSE(Mean Square Error)가 등장

#### MSE
- F = 집단간분산(각집단의 평균이 그랜드평균과 얼마나 떨어져있는가) / 집단내 분산(각 데이터가 각집단의 평균과 얼마나 떨어져 있는가)








## references
경영통계 / 유태종 교수님






















