---
layout: post
title: "경영빅데이터분석 중간정리"
excerpt_separator: "<!--more-->"
categories:
  - Data Science
tags:
  - 개론
---

# 빅데이터 정의

빅데이터란 기존의 데이터 분석에서 기존 방식으로 저장/관리/분석하기 
어려운 큰 규모의 복잡하고 실시간의 데이터를 말함
크게 3가지 특징을 갖는다.

- Variety : 기존 기업 내부데이터 뿐 아니라 sns,iot를 통한 개인이 생산해내는 매우 다양한 데이터(정형+비정형)
 또한, 데이터를 분석할 수 있는 여러 기법들이 생겼다.(머신러닝, 강화학습 등)

- Variety : 빅데이터를 다룰 수 있는 시스템의 연산속도가 비약적으로 상승함.
Scale up 측면 (그래픽 카드를 cpu대신 쓰는 gpgpu를 통해서 실시간 처리가 용이)
gpgpu의 첫 등장은 암진단을 위해 사용, 주로 그래픽연산에만 사용되다가 오픈소스화
엔비디아는 cuda라는 분산처리 알고리즘 기술을 통해 하나의 에코시스템을 형성함

- VOLUME : 분산처리의 발전으로 분석할 수 있는 양 자체를 크게 늘릴 수 있었음
Scale out 측면(하둡같이 여러대의 컴퓨터를 묶어서 한대 처럼 쓸수 있는 분산 컴퓨팅 시스템)
하둡은 여러대 저샤양 pc를 하나의 슈퍼 컴퓨터처럼 사용하는 구글 파일시스템을 근간으로 함
SPARK는 하둡의 hdfs와 달리 read only인 immutable in-momory를 통해 획기적인 속도 향상 이룸(ram활용)
최근의 메인스트림을 이룸

# 알파고 문제
알파고는 지금까지 바둑경기에 쌓인 승률과 기보를 사용하여 강화학습 기반의 monte carlo tree search
알고리즘을 활용함. 
몬테 카를로 트리 서치는 선택 - 확장 - 시뮬레이션 - 역전파의 과정으로 가장 가능성이 높아보이는 방향으로 행동을 결정하는 탐색 방법이다.
강화학습이란 기계학습의 한 영역으로 어떤 행동에 따른 보상을 주어 그 보상이 높아질 가능성을 계속 찾아서 학습하는 방법을 말함
TIC TAC TOE 빙고 게임의 원리와 같다.
tic tac toe 에서 x가 이기거나 지는 모든 xoxxooxoo는 승리 같은 950개 정도의 경우의수를 학습시켜서 확률이 높은 곳으로 가는 것


# 데이터 비즈니스 모델

빅데이터 비즈니스 모델은 차별화된 특징, 독점성, 저비용의 측면의 경쟁력을 가짐
즉, 저비용으로 보유한 데이터를 통해 차별화된 방법으로 분석하여 남들과 다른 시장우위를 가져감
데이터를 갖고 있는 카카오나 구글같은 기업은 시장을 독점할 수 있고 많은 업체들은 거기에 따라갈 수 밖에 없음
경영학적 측면에서 외부 환경을 자기한테 유리하게 끌고 올 수 있다는 의미
 
# GIT과 GIT HUB에 대해 섬령하고 GIT 과 서브버전(비전?)의 차이가 뭔지?
# 버전관리란 무엇인지 설명하시오 (동작원리 + GIT FLOW 다 언급해야)

버전관리 시스템잉란 파일 변화를 시간에 따라 기록했다가 나중에 특정 시점의 버전을 다시 꺼내올 수 있는 시스템이다.
예) 
1월2일.txt     1월 4일.txt 
먹다              잘먹다
입다              잘입다

1월5일에 사람들이 예전으로 바꿔달라고 컴플레인이 많이들어오면 1월2일로 롤백

그중 git은 분산 저장식 버전관리 시스템이고 svn은 중앙집중식 버전관리 시스템
(git은 네트워크 연결 없이 로컬에서도 사용)


Working Directory(local) <-> Staging Area <-> git directory(Repository)
                         	         1		        2

- 1 : Stage Fixes (git add~를 통해 Tracked file로 만듬) => 스냅샷 생김
- 2 : Commit을 통해 Tracked 된 파일들을 저장소에 저장
- staging area는 대기하는 장소라고 보면 됨


git flow는 여러 개발자들이 협업하는 도중 디버깅의 효율성 등 여러 이점을 가짐
여러 branch 단계에서 개발혹은 보수를 하다가 mater branch에 merge되어 배포가 된다.
hotfixes는 예정에 없이 큰 문제가 생길때 긴급한 수정을 한 뒤 master와 develop에 merge
relase branches는 아래에서 작업된 내용을 정식으로 배포하기 이전에 테스트하고 마스터로 올리는 역할
develop branches는 메인 개발 단계이고 feature branches는 작은 기능추가 후 develop으로 올림

git hub는 공유 저장소 역할



# PULL REQUEST의 단계 ( 포크 -> 복사 -> 브랜치 -> 커밋 -> 푸쉬 -> 풀리퀘스트

- fork - 원작자의 저장소를 복제함
- clone - 원격 저장소를 로컬 저장소로 다운로드
- branch - 마스터 브랜치에서 다른 작업할 브랜치 생성
- checkout - 그 브랜치로 변경
- source change - 수정 필요한 소스 변경
- commit - 변경한 소스를 로컬 저장소에 저장
- push - 로컬저장소의 작업 브랜치를 원격 저장소로
- pull request - 변경사항을 원작자에게 보냄(맞다고 생각하면 수정 - master branch에 반영)
오픈소스에 기여하는 효과 


# DATA ANALYSIS PROCESS
server에 누적된 데이터와 실시간 데이터를 수집, 병합하고
정제한 뒤 규모에 따라 환경을 정하고 분석 및 시각화를 함
데이터 분석은 한 사이클로 일정하게 흘러가는게 아니라 그때그때 분석하면서
이전 단계로 돌아갈 수 있고 계속 피드백 주고받음.

# SAMPLE VALANCING 왜 해야함?
통계학적인 설명력을 높이기 때문에 밸런싱을 잘 맞춰야 한다 WHY..?
단순 정확도만 보면 데이터 분석의 성능을 올바르게 측정하기 어려움 WHY..?

(암환자)  CONFUSION MATRIX 그리시오


TYPE 1 ERROR:
TYPE 2 ERROR:
ACCURACY RATE
F1-MEASURE
PRECISION

샘플링하는 방법 3가지!!
- 소수집단에 대한 OVERSAMPLING
- 다수집단에 대한 UNDERSAMPLING
- COST 함수를 통해 암환자 맞추면 +10,  틀리면 -10, 일반인 맞추면 +1, 틀리면 -1


# 트레이닝셋과 테스트셋을 왜나옴? / 벨리데이션 셋을 통해 뭐함?
# K-FOLD TEST / OVERFITTING에 대해 설명하시오

머신러닝 모델에서 데이터들을
트레이닝,테스트,벨리데이션 셋을 나누어 훈련, 테스트, 검증의 과정을 k회 진행하여 성능 도출
충분한 교차검증을 하지 않으면, 훈련한 데이터에만 최적화되는 과적합이 일어남
새로 들어오는 데이터에도 잘 작동하기 위해 사용
k-fold test란 데이터를 랜덤하게 k개로 쪼개서 교차하여 검증 => 정확도 



# 클라우드란 무엇인가? - 클라우드 상에서 데이터 분석이 어떻게 이루어지는가?

클라우드란 컴퓨팅 자원을 외부에 빌려서 쓰는 것을 말한다. 크게 saas(software as a service),
paas(platform as a service), iaas(infrastructure as a service) 로 나뉜다.
AWS도 서버 와 스토리지 등을 제공하기 때문에 회사는 규모를 예상해서 만들어야하는 온프레미스
방식에 비해 리스크와 초기비용을 줄일 수 있다. 사실상 보안문제도 클라우드가 더 좋다는 견해가 많아
최근에는 국내에서도 하이브리드 형으로라도 많이 도입하는 추세.
AWS를 예시로들면 EC2의 인스턴스를 한대의 컴퓨터로보고 성능을 정해서 만듬
그위에 운영체제나 분산분석 플랫폼을 구축해서 데이터 분석을 하게됨
AMI는 EC2의 환경등을 스냅샷으로 저장한 이미지로 후에 다른 인스턴스에 그대로 적용할 수 있음


























